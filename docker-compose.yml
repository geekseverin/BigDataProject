# =====================================================
# DOCKER COMPOSE - PROJET BIG DATA UCAO 2025
# Version corrig√©e sans erreurs de build context
# =====================================================

services:
  # =====================================================
  # HADOOP CLUSTER CONFIGURATION
  # =====================================================
  
  # Hadoop Base Image - shared by all Hadoop nodes
  hadoop-base:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-base/Dockerfile
    image: bigdata/hadoop-base:3.3.4
    networks:
      - bigdata-network

  # Hadoop Master Node (NameNode + ResourceManager)
  hadoop-master:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-master/Dockerfile
    container_name: hadoop-master
    hostname: hadoop-master
    ports:
      - "9870:9870"   # HDFS NameNode Web UI
      - "8088:8088"   # YARN ResourceManager Web UI
      - "19888:19888" # MapReduce JobHistory Server
      - "8020:8020"   # HDFS NameNode IPC
      - "8032:8032"   # YARN ResourceManager
    volumes:
      - ./config/hadoop:/opt/hadoop/etc/hadoop:ro
      - ./scripts:/opt/scripts:ro
      - ./data:/opt/data:ro
      - hadoop-master-data:/opt/hadoop/data
      - hadoop-master-logs:/opt/hadoop/logs
    environment:
      - HADOOP_ROLE=master
      - CLUSTER_NAME=bigdata-cluster
    networks:
      - bigdata-network
    depends_on:
      - hadoop-base

  # Hadoop Secondary NameNode
  hadoop-secondary:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-master/Dockerfile
    container_name: hadoop-secondary
    hostname: hadoop-secondary
    ports:
      - "9868:9868"   # Secondary NameNode Web UI
    volumes:
      - ./config/hadoop:/opt/hadoop/etc/hadoop:ro
      - ./scripts:/opt/scripts:ro
      - hadoop-secondary-data:/opt/hadoop/data
      - hadoop-secondary-logs:/opt/hadoop/logs
    environment:
      - HADOOP_ROLE=secondary
      - CLUSTER_NAME=bigdata-cluster
    networks:
      - bigdata-network
    depends_on:
      - hadoop-master

  # Hadoop Worker Node 1
  hadoop-worker-1:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-worker/Dockerfile
    container_name: hadoop-worker-1
    hostname: hadoop-worker-1
    ports:
      - "9864:9864"   # DataNode Web UI
      - "8042:8042"   # NodeManager Web UI
    volumes:
      - ./config/hadoop:/opt/hadoop/etc/hadoop:ro
      - ./scripts:/opt/scripts:ro
      - hadoop-worker1-data:/opt/hadoop/data
      - hadoop-worker1-logs:/opt/hadoop/logs
    environment:
      - HADOOP_ROLE=worker
      - WORKER_ID=1
    networks:
      - bigdata-network
    depends_on:
      - hadoop-master

  # Hadoop Worker Node 2
  hadoop-worker-2:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-worker/Dockerfile
    container_name: hadoop-worker-2
    hostname: hadoop-worker-2
    ports:
      - "9865:9864"   # DataNode Web UI
      - "8043:8042"   # NodeManager Web UI
    volumes:
      - ./config/hadoop:/opt/hadoop/etc/hadoop:ro
      - ./scripts:/opt/scripts:ro
      - hadoop-worker2-data:/opt/hadoop/data
      - hadoop-worker2-logs:/opt/hadoop/logs
    environment:
      - HADOOP_ROLE=worker
      - WORKER_ID=2
    networks:
      - bigdata-network
    depends_on:
      - hadoop-master

  # Hadoop Worker Node 3
  hadoop-worker-3:
    build:
      context: .
      dockerfile: dockerfiles/hadoop-worker/Dockerfile
    container_name: hadoop-worker-3
    hostname: hadoop-worker-3
    ports:
      - "9866:9864"   # DataNode Web UI
      - "8044:8042"   # NodeManager Web UI
    volumes:
      - ./config/hadoop:/opt/hadoop/etc/hadoop:ro
      - ./scripts:/opt/scripts:ro
      - hadoop-worker3-data:/opt/hadoop/data
      - hadoop-worker3-logs:/opt/hadoop/logs
    environment:
      - HADOOP_ROLE=worker
      - WORKER_ID=3
    networks:
      - bigdata-network
    depends_on:
      - hadoop-master

  # =====================================================
  # SPARK CLUSTER CONFIGURATION
  # =====================================================
  
  # Spark Master Node
  spark-master:
    image: bitnami/spark:3.4.1
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"   # Spark Master Web UI
      - "7077:7077"   # Spark Master port
    volumes:
      - ./scripts/spark:/opt/scripts:ro
      - ./config/spark:/opt/bitnami/spark/conf:ro
      - ./data:/opt/data:ro
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT_NUMBER=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    networks:
      - bigdata-network

  # Spark Worker Node 1
  spark-worker-1:
    image: bitnami/spark:3.4.1
    container_name: spark-worker-1
    hostname: spark-worker-1
    ports:
      - "8081:8081"   # Spark Worker Web UI
    volumes:
      - ./scripts/spark:/opt/scripts:ro
      - ./config/spark:/opt/bitnami/spark/conf:ro
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    networks:
      - bigdata-network
    depends_on:
      - spark-master

  # Spark Worker Node 2
  spark-worker-2:
    image: bitnami/spark:3.4.1
    container_name: spark-worker-2
    hostname: spark-worker-2
    ports:
      - "8082:8081"   # Spark Worker Web UI
    volumes:
      - ./scripts/spark:/opt/scripts:ro
      - ./config/spark:/opt/bitnami/spark/conf:ro
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    networks:
      - bigdata-network
    depends_on:
      - spark-master

  # =====================================================
  # MONGODB CONFIGURATION
  # =====================================================
  
  # MongoDB Database
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    hostname: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
      - ./scripts/setup/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=bigdata2025
      - MONGO_INITDB_DATABASE=bigdata
    networks:
      - bigdata-network

  # MongoDB Express - Web UI for MongoDB
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    ports:
      - "8090:8081"
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
      - ME_CONFIG_MONGODB_ADMINPASSWORD=bigdata2025
      - ME_CONFIG_MONGODB_SERVER=mongodb
      - ME_CONFIG_BASICAUTH_USERNAME=admin
      - ME_CONFIG_BASICAUTH_PASSWORD=admin
    networks:
      - bigdata-network
    depends_on:
      - mongodb

  # =====================================================
  # FLASK WEB APPLICATION
  # =====================================================
  
  # Flask Web Application
  web-app:
    build:
      context: .
      dockerfile: app/Dockerfile
    container_name: bigdata-webapp
    hostname: web-app
    ports:
      - "5000:5000"
    volumes:
      - ./app:/app:ro
      - app-results:/app/results
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - MONGODB_URI=mongodb://admin:bigdata2025@mongodb:27017/bigdata?authSource=admin
      - HADOOP_NAMENODE=http://hadoop-master:9870
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      - bigdata-network
    depends_on:
      - hadoop-master
      - spark-master
      - mongodb

  # =====================================================
  # NETWORK AND VOLUMES
  # =====================================================

networks:
  bigdata-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  # Hadoop volumes
  hadoop-master-data:
  hadoop-master-logs:
  hadoop-secondary-data:
  hadoop-secondary-logs:
  hadoop-worker1-data:
  hadoop-worker1-logs:
  hadoop-worker2-data:
  hadoop-worker2-logs:
  hadoop-worker3-data:
  hadoop-worker3-logs:
  
  # MongoDB volumes
  mongodb-data:
  
  # Application volumes
  app-results: