#!/bin/bash
# =====================================================
# SCRIPT PRINCIPAL D'ORCHESTRATION
# =====================================================
# D√©marre et configure tout l'√©cosyst√®me Big Data
# Utilisation: ./run_all.sh

set -e

echo "======================================================"
echo "üöÄ D√âMARRAGE COMPLET DU PROJET BIG DATA"
echo "======================================================"

# Variables globales
PROJECT_NAME="bigdata-project"
LOG_FILE="./logs/run_all.log"
START_TIME=$(date +%s)

# Cr√©er le r√©pertoire de logs
mkdir -p ./logs

# Fonction de logging
log() {
    local message="$1"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] $message" | tee -a "$LOG_FILE"
}

# Fonction d'affichage avec couleurs
print_step() {
    local step="$1"
    local description="$2"
    echo ""
    echo "======================================================"
    echo "üìã √âTAPE $step: $description"
    echo "======================================================"
}

# Fonction de v√©rification des pr√©requis
check_requirements() {
    print_step "1" "V√âRIFICATION DES PR√âREQUIS"
    
    # V√©rifier Docker
    if ! command -v docker &> /dev/null; then
        echo "‚ùå Docker non install√©"
        exit 1
    fi
    echo "‚úÖ Docker disponible: $(docker --version)"
    
    # V√©rifier Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        echo "‚ùå Docker Compose non install√©"
        exit 1
    fi
    echo "‚úÖ Docker Compose disponible: $(docker-compose --version)"
    
    # V√©rifier l'espace disque (minimum 10GB)
    local available_space=$(df . | awk 'NR==2 {print $4}')
    if [ "$available_space" -lt 10485760 ]; then  # 10GB en KB
        echo "‚ö†Ô∏è  Espace disque faible: $(($available_space / 1024 / 1024))GB disponibles"
        echo "üí° Recommandation: Lib√©rer plus de 10GB d'espace"
    else
        echo "‚úÖ Espace disque suffisant: $(($available_space / 1024 / 1024))GB disponibles"
    fi
    
    # V√©rifier la m√©moire
    local available_memory=$(free -m | awk 'NR==2{printf "%.0f", $7}')
    if [ "$available_memory" -lt 4096 ]; then
        echo "‚ö†Ô∏è  M√©moire disponible faible: ${available_memory}MB"
        echo "üí° Recommandation: Fermer des applications pour lib√©rer de la m√©moire"
    else
        echo "‚úÖ M√©moire suffisante: ${available_memory}MB disponibles"
    fi
    
    # V√©rifier les fichiers de donn√©es
    if [ ! -f "./data/sample_data.csv" ] || [ ! -f "./data/sales_data.csv" ]; then
        echo "‚ùå Fichiers de donn√©es manquants dans ./data/"
        exit 1
    fi
    echo "‚úÖ Fichiers de donn√©es pr√©sents"
    
    log "Pr√©requis v√©rifi√©s avec succ√®s"
}

# Fonction de nettoyage (optionnel)
cleanup_previous() {
    print_step "2" "NETTOYAGE ENVIRONNEMENT PR√âC√âDENT"
    
    echo "üßπ Nettoyage des conteneurs pr√©c√©dents..."
    
    # Arr√™ter les conteneurs existants
    docker-compose down -v 2>/dev/null || true
    
    # Supprimer les images orphelines (optionnel)
    echo "üóëÔ∏è  Nettoyage des ressources Docker..."
    docker system prune -f > /dev/null 2>&1 || true
    
    # Nettoyer les logs pr√©c√©dents
    rm -f ./logs/*.log 2>/dev/null || true
    
    echo "‚úÖ Environnement nettoy√©"
    log "Environnement nettoy√©"
}

# Fonction de construction et d√©marrage
build_and_start() {
    print_step "3" "CONSTRUCTION ET D√âMARRAGE DES SERVICES"
    
    echo "üî® Construction des images Docker..."
    docker-compose build --no-cache | tee -a "$LOG_FILE"
    
    echo "üöÄ D√©marrage des services..."
    docker-compose up -d | tee -a "$LOG_FILE"
    
    echo "‚è≥ Attente du d√©marrage des services (60s)..."
    sleep 60
    
    # V√©rifier que les services sont d√©marr√©s
    echo "üîç V√©rification des services:"
    local services=("hadoop-master" "hadoop-secondary" "hadoop-worker-1" "hadoop-worker-2" "hadoop-worker-3" "spark-master" "spark-worker-1" "spark-worker-2" "mongodb")
    
    for service in "${services[@]}"; do
        if docker ps --format "table {{.Names}}" | grep -q "^$service$"; then
            echo "   ‚úÖ $service: D√©marr√©"
        else
            echo "   ‚ùå $service: Non d√©marr√©"
            echo "üîç Logs du service $service:"
            docker logs "$service" --tail 20
        fi
    done
    
    log "Services d√©marr√©s"
}

# Fonction d'initialisation Hadoop
initialize_hadoop() {
    print_step "4" "INITIALISATION HADOOP"
    
    echo "üìä Lancement de l'initialisation Hadoop..."
    
    # Rendre le script ex√©cutable
    chmod +x ./scripts/setup/init-hadoop.sh
    
    # Lancer l'initialisation
    ./scripts/setup/init-hadoop.sh | tee -a "$LOG_FILE"
    
    echo "‚úÖ Hadoop initialis√©"
    log "Hadoop initialis√© avec succ√®s"
}

# Fonction d'initialisation Spark
initialize_spark() {
    print_step "5" "INITIALISATION SPARK"
    
    echo "‚ö° Lancement de l'initialisation Spark..."
    
    # Rendre le script ex√©cutable
    chmod +x ./scripts/setup/init-spark.sh
    
    # Lancer l'initialisation
    ./scripts/setup/init-spark.sh | tee -a "$LOG_FILE"
    
    echo "‚úÖ Spark initialis√©"
    log "Spark initialis√© avec succ√®s"
}

# Fonction de chargement et traitement des donn√©es
load_and_process_data() {
    print_step "6" "CHARGEMENT ET TRAITEMENT DES DONN√âES"
    
    echo "üìä Lancement du chargement des donn√©es..."
    
    # Rendre le script ex√©cutable
    chmod +x ./scripts/setup/load-data.sh
    
    # Lancer le chargement et traitement
    ./scripts/setup/load-data.sh | tee -a "$LOG_FILE"
    
    echo "‚úÖ Donn√©es charg√©es et trait√©es"
    log "Donn√©es charg√©es et analyses termin√©es"
}

# Fonction de d√©marrage de l'application web
start_web_application() {
    print_step "7" "D√âMARRAGE APPLICATION WEB"
    
    echo "üåê D√©marrage de l'application web Flask..."
    
    # D√©marrer l'application web
    docker-compose up -d web-app
    
    # Attendre le d√©marrage
    echo "‚è≥ Attente du d√©marrage de l'application (30s)..."
    sleep 30
    
    # V√©rifier que l'application est accessible
    local count=0
    while ! curl -s http://localhost:5000 > /dev/null 2>&1; do
        if [ $count -ge 10 ]; then
            echo "‚ö†Ô∏è  Application web non accessible apr√®s 60s"
            break
        fi
        echo "   Tentative de connexion $(($count + 1))/10..."
        sleep 6
        ((count++))
    done
    
    if curl -s http://localhost:5000 > /dev/null 2>&1; then
        echo "‚úÖ Application web accessible"
    else
        echo "‚ùå Application web non accessible"
        echo "üîç Logs de l'application:"
        docker logs bigdata-webapp --tail 20
    fi
    
    log "Application web d√©marr√©e"
}

# Fonction d'affichage du statut final
display_final_status() {
    print_step "8" "STATUT FINAL DU SYST√àME"
    
    local end_time=$(date +%s)
    local duration=$(($end_time - $start_time))
    
    echo "‚è±Ô∏è  Temps total d'initialisation: $((duration / 60))m $((duration % 60))s"
    echo ""
    
    # Statut des conteneurs
    echo "üìã Statut des conteneurs:"
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "(hadoop|spark|mongo|webapp)"
    
    echo ""
    echo "üîó URLs d'acc√®s:"
    echo "   üìä Application Web:      http://localhost:5000"
    echo "   üóÑÔ∏è  Hadoop NameNode:     http://localhost:9870"
    echo "   ‚ö° Spark Master:         http://localhost:8080"
    echo "   üçÉ MongoDB Express:      http://localhost:8090"
    echo "   üìà YARN ResourceManager: http://localhost:8088"
    
    echo ""
    echo "üìÅ Donn√©es et r√©sultats:"
    echo "   üìä Donn√©es HDFS:         /data/input/ et /data/output/"
    echo "   üçÉ Collections MongoDB:  bigdata.sales, bigdata.customers"
    echo "   üìã Logs syst√®me:         ./logs/"
    
    # Afficher l'utilisation des ressources
    echo ""
    echo "üíª Utilisation des ressources:"
    echo "   üê≥ Conteneurs Docker:    $(docker ps | wc -l) actifs"
    echo "   üíæ Utilisation m√©moire:  $(docker stats --no-stream --format 'table {{.Container}}\t{{.MemUsage}}' | tail -n +2 | head -5)"
    
    log "D√©ploiement termin√© - dur√©e: ${duration}s"
}

# Fonction de test de sant√© du syst√®me
health_check() {
    echo ""
    echo "üè• V√âRIFICATIONS DE SANT√â:"
    
    # Test HDFS
    if docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -ls /'" > /dev/null 2>&1; then
        echo "   ‚úÖ HDFS: Op√©rationnel"
    else
        echo "   ‚ùå HDFS: Probl√®me d√©tect√©"
    fi
    
    # Test Spark
    if curl -s http://localhost:8080 > /dev/null 2>&1; then
        echo "   ‚úÖ Spark: Accessible"
    else
        echo "   ‚ùå Spark: Non accessible"
    fi
    
    # Test MongoDB
    if docker exec mongodb mongosh --eval "db.runCommand('ping')" > /dev/null 2>&1; then
        echo "   ‚úÖ MongoDB: Op√©rationnel"
    else
        echo "   ‚ùå MongoDB: Probl√®me d√©tect√©"
    fi
    
    # Test Application Web
    if curl -s http://localhost:5000 > /dev/null 2>&1; then
        echo "   ‚úÖ Application Web: Accessible"
    else
        echo "   ‚ùå Application Web: Non accessible"
    fi
}

# Fonction de gestion des erreurs
handle_error() {
    local exit_code=$?
    local line_number=$1
    
    echo ""
    echo "‚ùå ERREUR D√âTECT√âE √Ä LA LIGNE $line_number (CODE: $exit_code)"
    echo "üìã V√©rification des logs:"
    
    # Afficher les derniers logs
    if [ -f "$LOG_FILE" ]; then
        echo "üîç Derni√®res entr√©es du log:"
        tail -20 "$LOG_FILE"
    fi
    
    echo ""
    echo "üõ†Ô∏è  ACTIONS DE D√âPANNAGE:"
    echo "1. V√©rifier les logs: docker-compose logs [service]"
    echo "2. Red√©marrer un service: docker-compose restart [service]" 
    echo "3. R√©initialiser compl√®tement: docker-compose down -v && ./run_all.sh"
    echo "4. V√©rifier l'espace disque: df -h"
    echo "5. V√©rifier la m√©moire: free -h"
    
    log "Erreur d√©tect√©e - ligne $line_number - code $exit_code"
    
    exit $exit_code
}

# Configuration du trap pour gestion d'erreurs
trap 'handle_error $LINENO' ERR

# Fonction principale
main() {
    echo "üöÄ D√âMARRAGE DU PROJET BIG DATA UCAO 2024-2025"
    echo "üìÖ $(date)"
    echo "üìÅ R√©pertoire: $(pwd)"
    echo ""
    
    log "=== D√âMARRAGE DU D√âPLOIEMENT ==="
    
    # V√©rifier si l'utilisateur veut un d√©ploiement propre
    if [ "$1" == "--clean" ]; then
        cleanup_previous
    else
        echo "üí° Pour un d√©ploiement propre: ./run_all.sh --clean"
        echo ""
    fi
    
    # S√©quence de d√©ploiement
    check_requirements
    build_and_start
    initialize_hadoop
    initialize_spark
    load_and_process_data
    start_web_application
    display_final_status
    health_check
    
    echo ""
    echo "======================================================"
    echo "üéâ D√âPLOIEMENT TERMIN√â AVEC SUCC√àS!"
    echo "======================================================"
    echo ""
    echo "üöÄ Votre environnement Big Data est pr√™t!"
    echo "üìä Acc√©dez √† l'application: http://localhost:5000"
    echo "üìã Consultez les logs: cat ./logs/run_all.log"
    echo ""
    echo "üìö Commandes utiles:"
    echo "   ‚Ä¢ Arr√™ter:        docker-compose down"
    echo "   ‚Ä¢ Red√©marrer:     docker-compose restart"
    echo "   ‚Ä¢ Logs:           docker-compose logs [service]"
    echo "   ‚Ä¢ Status:         docker-compose ps"
    echo ""
    echo "üéì Bon apprentissage du Big Data!"
    
    log "=== D√âPLOIEMENT TERMIN√â AVEC SUCC√àS ==="
}

# Point d'entr√©e
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi