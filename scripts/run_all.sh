#!/bin/bash
# =====================================================
# SCRIPT PRINCIPAL D'ORCHESTRATION
# =====================================================
# DÃ©marre et configure tout l'Ã©cosystÃ¨me Big Data
# Utilisation: ./run_all.sh

set -e

echo "======================================================"
echo "ğŸš€ DÃ‰MARRAGE COMPLET DU PROJET BIG DATA"
echo "======================================================"

# Variables globales
PROJECT_NAME="bigdata-project"
LOG_FILE="./logs/run_all.log"
START_TIME=$(date +%s)

# CrÃ©er le rÃ©pertoire de logs
mkdir -p ./logs

# Fonction de logging
log() {
    local message="$1"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] $message" | tee -a "$LOG_FILE"
}

# Fonction d'affichage avec couleurs
print_step() {
    local step="$1"
    local description="$2"
    echo ""
    echo "======================================================"
    echo "ğŸ“‹ Ã‰TAPE $step: $description"
    echo "======================================================"
}

# Fonction de vÃ©rification des prÃ©requis
check_requirements() {
    print_step "1" "VÃ‰RIFICATION DES PRÃ‰REQUIS"
    
    # VÃ©rifier Docker
    if ! command -v docker &> /dev/null; then
        echo "âŒ Docker non installÃ©"
        exit 1
    fi
    echo "âœ… Docker disponible: $(docker --version)"
    
    # VÃ©rifier Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        echo "âŒ Docker Compose non installÃ©"
        exit 1
    fi
    echo "âœ… Docker Compose disponible: $(docker-compose --version)"
    
    # VÃ©rifier l'espace disque (minimum 10GB)
    local available_space=$(df . | awk 'NR==2 {print $4}')
    if [ "$available_space" -lt 10485760 ]; then  # 10GB en KB
        echo "âš ï¸  Espace disque faible: $(($available_space / 1024 / 1024))GB disponibles"
        echo "ğŸ’¡ Recommandation: LibÃ©rer plus de 10GB d'espace"
    else
        echo "âœ… Espace disque suffisant: $(($available_space / 1024 / 1024))GB disponibles"
    fi
    
    # VÃ©rifier la mÃ©moire
    local available_memory=$(free -m | awk 'NR==2{printf "%.0f", $7}')
    if [ "$available_memory" -lt 4096 ]; then
        echo "âš ï¸  MÃ©moire disponible faible: ${available_memory}MB"
        echo "ğŸ’¡ Recommandation: Fermer des applications pour libÃ©rer de la mÃ©moire"
    else
        echo "âœ… MÃ©moire suffisante: ${available_memory}MB disponibles"
    fi
    
    # VÃ©rifier les fichiers de donnÃ©es
    if [ ! -f "./data/sample_data.csv" ] || [ ! -f "./data/sales_data.csv" ]; then
        echo "âŒ Fichiers de donnÃ©es manquants dans ./data/"
        exit 1
    fi
    echo "âœ… Fichiers de donnÃ©es prÃ©sents"
    
    log "PrÃ©requis vÃ©rifiÃ©s avec succÃ¨s"
}

# Fonction de nettoyage (optionnel)
cleanup_previous() {
    print_step "2" "NETTOYAGE ENVIRONNEMENT PRÃ‰CÃ‰DENT"
    
    echo "ğŸ§¹ Nettoyage des conteneurs prÃ©cÃ©dents..."
    
    # ArrÃªter les conteneurs existants
    docker-compose down -v 2>/dev/null || true
    
    # Supprimer les images orphelines (optionnel)
    echo "ğŸ—‘ï¸  Nettoyage des ressources Docker..."
    docker system prune -f > /dev/null 2>&1 || true
    
    # Nettoyer les logs prÃ©cÃ©dents
    rm -f ./logs/*.log 2>/dev/null || true
    
    echo "âœ… Environnement nettoyÃ©"
    log "Environnement nettoyÃ©"
}

# Fonction de construction et dÃ©marrage
build_and_start() {
    print_step "3" "CONSTRUCTION ET DÃ‰MARRAGE DES SERVICES"
    
    echo "ğŸ”¨ Construction des images Docker..."
    docker-compose build --no-cache | tee -a "$LOG_FILE"
    
    echo "ğŸš€ DÃ©marrage des services..."
    docker-compose up -d | tee -a "$LOG_FILE"
    
    echo "â³ Attente du dÃ©marrage des services (60s)..."
    sleep 60
    
    # VÃ©rifier que les services sont dÃ©marrÃ©s
    echo "ğŸ” VÃ©rification des services:"
    local services=("hadoop-master" "hadoop-secondary" "hadoop-worker-1" "hadoop-worker-2" "hadoop-worker-3" "spark-master" "spark-worker-1" "spark-worker-2" "mongodb")
    
    for service in "${services[@]}"; do
        if docker ps --format "table {{.Names}}" | grep -q "^$service$"; then
            echo "   âœ… $service: DÃ©marrÃ©"
        else
            echo "   âŒ $service: Non dÃ©marrÃ©"
            echo "ğŸ” Logs du service $service:"
            docker logs "$service" --tail 20
        fi
    done
    
    log "Services dÃ©marrÃ©s"
}

# Fonction d'initialisation Hadoop
initialize_hadoop() {
    print_step "4" "INITIALISATION HADOOP"
    
    echo "ğŸ“Š Lancement de l'initialisation Hadoop..."
    
    # Rendre le script exÃ©cutable
    chmod +x ./scripts/setup/init-hadoop.sh
    
    # Lancer l'initialisation
    ./scripts/setup/init-hadoop.sh | tee -a "$LOG_FILE"
    
    echo "âœ… Hadoop initialisÃ©"
    log "Hadoop initialisÃ© avec succÃ¨s"
}

# Fonction d'initialisation Spark
initialize_spark() {
    print_step "5" "INITIALISATION SPARK"
    
    echo "âš¡ Lancement de l'initialisation Spark..."
    
    # Rendre le script exÃ©cutable
    chmod +x ./scripts/setup/init-spark.sh
    
    # Lancer l'initialisation
    ./scripts/setup/init-spark.sh | tee -a "$LOG_FILE"
    
    echo "âœ… Spark initialisÃ©"
    log "Spark initialisÃ© avec succÃ¨s"
}

# Fonction de chargement et traitement des donnÃ©es
load_and_process_data() {
    print_step "6" "CHARGEMENT ET TRAITEMENT DES DONNÃ‰ES"
    
    echo "ğŸ“Š Lancement du chargement des donnÃ©es..."
    
    # Rendre le script exÃ©cutable
    chmod +x ./scripts/setup/load-data.sh
    
    # Lancer le chargement et traitement
    ./scripts/setup/load-data.sh | tee -a "$LOG_FILE"
    
    echo "âœ… DonnÃ©es chargÃ©es et traitÃ©es"
    log "DonnÃ©es chargÃ©es et analyses terminÃ©es"
}

# Fonction de dÃ©marrage de l'application web
start_web_application() {
    print_step "7" "DÃ‰MARRAGE APPLICATION WEB"
    
    echo "ğŸŒ DÃ©marrage de l'application web Flask..."
    
    # DÃ©marrer l'application web
    docker-compose up -d web-app
    
    # Attendre le dÃ©marrage
    echo "â³ Attente du dÃ©marrage de l'application (30s)..."
    sleep 30
    
    # VÃ©rifier que l'application est accessible
    local count=0
    while ! curl -s http://localhost:5000 > /dev/null 2>&1; do
        if [ $count -ge 10 ]; then
            echo "âš ï¸  Application web non accessible aprÃ¨s 60s"
            break
        fi
        echo "   Tentative de connexion $(($count + 1))/10..."
        sleep 6
        ((count++))
    done
    
    if curl -s http://localhost:5000 > /dev/null 2>&1; then
        echo "âœ… Application web accessible"
    else
        echo "âŒ Application web non accessible"
        echo "ğŸ” Logs de l'application:"
        docker logs bigdata-webapp --tail 20
    fi
    
    log "Application web dÃ©marrÃ©e"
}

# Fonction d'affichage du statut final
display_final_status() {
    print_step "8" "STATUT FINAL DU SYSTÃˆME"
    
    local end_time=$(date +%s)
    local duration=$(($end_time - $start_time))
    
    echo "â±ï¸  Temps total d'initialisation: $((duration / 60))m $((duration % 60))s"
    echo ""
    
    # Statut des conteneurs
    echo "ğŸ“‹ Statut des conteneurs:"
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "(hadoop|spark|mongo|webapp)"
    
    echo ""
    echo "ğŸ”— URLs d'accÃ¨s:"
    echo "   ğŸ“Š Application Web:      http://localhost:5000"
    echo "   ğŸ—„ï¸  Hadoop NameNode:     http://localhost:9870"
    echo "   âš¡ Spark Master:         http://localhost:8080"
    echo "   ğŸƒ MongoDB Express:      http://localhost:8090"
    echo "   ğŸ“ˆ YARN ResourceManager: http://localhost:8088"
    
    echo ""
    echo "ğŸ“ DonnÃ©es et rÃ©sultats:"
    echo "   ğŸ“Š DonnÃ©es HDFS:         /data/input/ et /data/output/"
    echo "   ğŸƒ Collections MongoDB:  bigdata.sales, bigdata.customers"
    echo "   ğŸ“‹ Logs systÃ¨me:         ./logs/"
    
    # Afficher l'utilisation des ressources
    echo ""
    echo "ğŸ’» Utilisation des ressources:"
    echo "   ğŸ³ Conteneurs Docker:    $(docker ps | wc -l) actifs"
    echo "   ğŸ’¾ Utilisation mÃ©moire:  $(docker stats --no-stream --format 'table {{.Container}}\t{{.MemUsage}}' | tail -n +2 | head -5)"
    
    log "DÃ©ploiement terminÃ© - durÃ©e: ${duration}s"
}

# Fonction de test de santÃ© du systÃ¨me
health_check() {
    echo ""
    echo "ğŸ¥ VÃ‰RIFICATIONS DE SANTÃ‰:"
    
    # Test HDFS
    if docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -ls /'" > /dev/null 2>&1; then
        echo "   âœ… HDFS: OpÃ©rationnel"
    else
        echo "   âŒ HDFS: ProblÃ¨me dÃ©tectÃ©"
    fi
    
    # Test Spark
    if curl -s http://localhost:8080 > /dev/null 2>&1; then
        echo "   âœ… Spark: Accessible"
    else
        echo "   âŒ Spark: Non accessible"
    fi
    
    # Test MongoDB
    if docker exec mongodb mongosh --eval "db.runCommand('ping')" > /dev/null 2>&1; then
        echo "   âœ… MongoDB: OpÃ©rationnel"
    else
        echo "   âŒ MongoDB: ProblÃ¨me dÃ©tectÃ©"
    fi
    
    # Test Application Web
    if curl -s http://localhost:5000 > /dev/null 2>&1; then
        echo "   âœ… Application Web: Accessible"
    else
        echo "   âŒ Application Web: Non accessible"
    fi
}

# Fonction de gestion des erreurs
handle_error() {
    local exit_code=$?
    local line_number=$1
    
    echo ""
    echo "âŒ ERREUR DÃ‰TECTÃ‰E Ã€ LA LIGNE $line_number (CODE: $exit_code)"
    echo "ğŸ“‹ VÃ©rification des logs:"
    
    # Afficher les derniers logs
    if [ -f "$LOG_FILE" ]; then
        echo "ğŸ” DerniÃ¨res entrÃ©es du log:"
        tail -20 "$LOG_FILE"
    fi
    
    echo ""
    echo "ğŸ› ï¸  ACTIONS DE DÃ‰PANNAGE:"
    echo "1. VÃ©rifier les logs: docker-compose logs [service]"
    echo "2. RedÃ©marrer un service: docker-compose restart [service]" 
    echo "3. RÃ©initialiser complÃ¨tement: docker-compose down -v && ./run_all.sh"
    echo "4. VÃ©rifier l'espace disque: df -h"
    echo "5. VÃ©rifier la mÃ©moire: free -h"
    
    log "Erreur dÃ©tectÃ©e - ligne $line_number - code $exit_code"
    
    exit $exit_code
}

# Configuration du trap pour gestion d'erreurs
trap 'handle_error $LINENO' ERR

# Fonction principale
main() {
    echo "ğŸš€ DÃ‰MARRAGE DU PROJET BIG DATA UCAO 2024-2025"
    echo "ğŸ“… $(date)"
    echo "ğŸ“ RÃ©pertoire: $(pwd)"
    echo ""
    
    log "=== DÃ‰MARRAGE DU DÃ‰PLOIEMENT ==="
    
    # VÃ©rifier si l'utilisateur veut un dÃ©ploiement propre
    if [ "$1" == "--clean" ]; then
        cleanup_previous
    else
        echo "ğŸ’¡ Pour un dÃ©ploiement propre: ./run_all.sh --clean"
        echo ""
    fi
    
    # SÃ©quence de dÃ©ploiement
    check_requirements
    build_and_start
    initialize_hadoop
    initialize_spark
    load_and_process_data
    start_web_application
    display_final_status
    health_check
    
    echo ""
    echo "======================================================"
    echo "ğŸ‰ DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS!"
    echo "======================================================"
    echo ""
    echo "ğŸš€ Votre environnement Big Data est prÃªt!"
    echo "ğŸ“Š AccÃ©dez Ã  l'application: http://localhost:5000"
    echo "ğŸ“‹ Consultez les logs: cat ./logs/run_all.log"
    echo ""
    echo "ğŸ“š Commandes utiles:"
    echo "   â€¢ ArrÃªter:        docker-compose down"
    echo "   â€¢ RedÃ©marrer:     docker-compose restart"
    echo "   â€¢ Logs:           docker-compose logs [service]"
    echo "   â€¢ Status:         docker-compose ps"
    echo ""
    echo "ğŸ“ Bon apprentissage du Big Data!"
    
    log "=== DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS ==="
}

# Point d'entrÃ©e
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi