#!/bin/bash
# =====================================================
# SCRIPT D'INITIALISATION HADOOP CLUSTER
# =====================================================
# Initialise le cluster Hadoop et configure HDFS
# Utilisation: ./init-hadoop.sh

set -e  # ArrÃªter en cas d'erreur

echo "======================================================"
echo "ğŸš€ INITIALISATION DU CLUSTER HADOOP"
echo "======================================================"

# Variables de configuration
HADOOP_MASTER="hadoop-master"
HDFS_USER="hadoop"
TIMEOUT=300  # 5 minutes timeout

# Fonction pour attendre qu'un service soit disponible
wait_for_service() {
    local host=$1
    local port=$2
    local service_name=$3
    local timeout=$4
    
    echo "â³ Attente du service $service_name sur $host:$port..."
    
    local count=0
    while ! nc -z $host $port 2>/dev/null; do
        if [ $count -ge $timeout ]; then
            echo "âŒ Timeout: $service_name non disponible aprÃ¨s ${timeout}s"
            return 1
        fi
        echo "   Tentative $((count + 1))/$timeout - Service $service_name pas encore prÃªt..."
        sleep 1
        ((count++))
    done
    
    echo "âœ… Service $service_name disponible"
    return 0
}

# Fonction pour vÃ©rifier le statut HDFS
check_hdfs_status() {
    echo "ğŸ” VÃ©rification du statut HDFS..."
    
    if docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfsadmin -report'" 2>/dev/null | grep -q "Live datanodes"; then
        echo "âœ… HDFS opÃ©rationnel"
        return 0
    else
        echo "âŒ HDFS non opÃ©rationnel"
        return 1
    fi
}

# Fonction principale d'initialisation
initialize_hadoop() {
    echo "ğŸ”§ Initialisation du cluster Hadoop..."
    
    # 1. Attendre que tous les conteneurs soient en cours d'exÃ©cution
    echo "ğŸ“‹ VÃ©rification des conteneurs..."
    
    local containers=("hadoop-master" "hadoop-secondary" "hadoop-worker-1" "hadoop-worker-2" "hadoop-worker-3")
    for container in "${containers[@]}"; do
        if ! docker ps --format "table {{.Names}}" | grep -q "^$container$"; then
            echo "âŒ Conteneur $container non trouvÃ© ou non dÃ©marrÃ©"
            echo "ğŸ’¡ ExÃ©cutez: docker-compose up -d"
            exit 1
        fi
        echo "âœ… Conteneur $container en cours d'exÃ©cution"
    done
    
    # 2. Attendre que les services Hadoop soient prÃªts
    echo "ğŸ”„ Attente des services Hadoop..."
    wait_for_service $HADOOP_MASTER 9870 "NameNode" 60
    wait_for_service $HADOOP_MASTER 8088 "ResourceManager" 60
    
    # Attendre un peu plus pour la stabilisation
    echo "â±ï¸  Stabilisation des services (30s)..."
    sleep 30
    
    # 3. VÃ©rifier le statut HDFS
    if ! check_hdfs_status; then
        echo "âš ï¸  HDFS pas encore complÃ¨tement initialisÃ©, tentative de rÃ©cupÃ©ration..."
        
        # RedÃ©marrer les services si nÃ©cessaire
        echo "ğŸ”„ RedÃ©marrage des services HDFS..."
        docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/sbin/stop-dfs.sh'" || true
        sleep 5
        docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/sbin/start-dfs.sh'"
        
        # Attendre et vÃ©rifier Ã  nouveau
        sleep 30
        if ! check_hdfs_status; then
            echo "âŒ Impossible d'initialiser HDFS correctement"
            exit 1
        fi
    fi
    
    echo "âœ… Cluster Hadoop initialisÃ© avec succÃ¨s"
}

# Fonction pour crÃ©er la structure de rÃ©pertoires HDFS
setup_hdfs_directories() {
    echo "ğŸ“ CrÃ©ation de la structure de rÃ©pertoires HDFS..."
    
    local directories=(
        "/user"
        "/user/hadoop"
        "/user/root"
        "/data"
        "/data/input"
        "/data/output"
        "/data/output/pig"
        "/data/output/spark"
        "/spark-logs"
        "/spark-checkpoints"
        "/tmp"
    )
    
    for dir in "${directories[@]}"; do
        echo "   CrÃ©ation du rÃ©pertoire: $dir"
        docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -mkdir -p $dir'" || {
            echo "âš ï¸  RÃ©pertoire $dir existe dÃ©jÃ  ou erreur de crÃ©ation"
        }
    done
    
    # DÃ©finir les permissions
    echo "ğŸ” Configuration des permissions HDFS..."
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 755 /user'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /data'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /data/input'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /data/output'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /tmp'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /spark-logs'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -chmod 777 /spark-checkpoints'"
    
    echo "âœ… Structure de rÃ©pertoires HDFS crÃ©Ã©e"
}

# Fonction pour charger les donnÃ©es initiales
load_initial_data() {
    echo "ğŸ“Š Chargement des donnÃ©es initiales dans HDFS..."
    
    # VÃ©rifier la prÃ©sence des fichiers de donnÃ©es
    if [ ! -f "./data/sample_data.csv" ] || [ ! -f "./data/sales_data.csv" ]; then
        echo "âš ï¸  Fichiers de donnÃ©es non trouvÃ©s dans ./data/"
        echo "ğŸ’¡ Assurez-vous que sample_data.csv et sales_data.csv sont prÃ©sents"
        return 1
    fi
    
    # Copier les fichiers vers le conteneur master
    echo "ğŸ“‹ Copie des fichiers vers le conteneur master..."
    docker cp ./data/sample_data.csv hadoop-master:/tmp/
    docker cp ./data/sales_data.csv hadoop-master:/tmp/
    
    # Charger dans HDFS
    echo "â¬†ï¸  Upload vers HDFS..."
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -put -f /tmp/sample_data.csv /data/input/'"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -put -f /tmp/sales_data.csv /data/input/'"
    
    # VÃ©rifier le chargement
    echo "ğŸ” VÃ©rification des donnÃ©es dans HDFS..."
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -ls /data/input/'"
    
    # Afficher les tailles des fichiers
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -du -h /data/input/'"
    
    echo "âœ… DonnÃ©es initiales chargÃ©es avec succÃ¨s"
}

# Fonction pour afficher les informations du cluster
display_cluster_info() {
    echo "======================================================"
    echo "ğŸ“Š INFORMATIONS DU CLUSTER HADOOP"
    echo "======================================================"
    
    # Rapport HDFS
    echo "ğŸ—„ï¸  Rapport HDFS:"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfsadmin -report'" | head -20
    
    echo ""
    echo "ğŸ”— URLs d'accÃ¨s:"
    echo "   NameNode Web UI:     http://localhost:9870"
    echo "   ResourceManager:     http://localhost:8088"
    echo "   JobHistory Server:   http://localhost:19888"
    echo "   Secondary NameNode:  http://localhost:9868"
    
    echo ""
    echo "ğŸ“ Contenu HDFS /data/input/:"
    docker exec hadoop-master bash -c "su - hadoop -c '$HADOOP_HOME/bin/hdfs dfs -ls /data/input/'" || echo "   Aucun fichier trouvÃ©"
    
    echo ""
    echo "âš™ï¸  Services Java actifs sur le master:"
    docker exec hadoop-master bash -c "jps"
    
    echo ""
    echo "ğŸ¯ Utilisation mÃ©moire:"
    docker exec hadoop-master bash -c "free -h"
}

# Fonction de nettoyage en cas d'erreur
cleanup_on_error() {
    echo "ğŸ§¹ Nettoyage en cas d'erreur..."
    echo "âš ï¸  Pour rÃ©initialiser complÃ¨tement:"
    echo "   docker-compose down -v"
    echo "   docker-compose up --build -d"
}

# Fonction principale
main() {
    echo "ğŸš€ DÃ©marrage de l'initialisation Hadoop..."
    
    # VÃ©rifier que Docker Compose est en cours d'exÃ©cution
    if ! docker-compose ps | grep -q "Up"; then
        echo "âŒ Les services ne semblent pas Ãªtre dÃ©marrÃ©s"
        echo "ğŸ’¡ ExÃ©cutez d'abord: docker-compose up -d"
        exit 1
    fi
    
    # Trap pour nettoyage en cas d'erreur
    trap cleanup_on_error ERR
    
    # SÃ©quence d'initialisation
    initialize_hadoop
    setup_hdfs_directories
    load_initial_data
    display_cluster_info
    
    echo ""
    echo "======================================================"
    echo "ğŸ‰ CLUSTER HADOOP INITIALISÃ‰ AVEC SUCCÃˆS!"
    echo "======================================================"
    echo "âœ… NameNode opÃ©rationnel"
    echo "âœ… DataNodes connectÃ©s"
    echo "âœ… ResourceManager actif"
    echo "âœ… DonnÃ©es chargÃ©es dans HDFS"
    echo ""
    echo "ğŸš€ PrÃªt pour l'analyse Big Data!"
    echo "ğŸ’¡ Prochaine Ã©tape: ./scripts/setup/init-spark.sh"
}

# Point d'entrÃ©e
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi